{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd, qr\n",
    "from scipy.sparse.linalg import svds\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_threshold(x, threshold):\n",
    "    return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)\n",
    "def hard_threshold(x, threshold):\n",
    "    return x * (np.abs(x) >= threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(U, Sig, V, mu_U, mu_V):\n",
    "    '''\n",
    "    Trims the input matrices U and V to ensure that their row norms are below\n",
    "    certain thresholds, and then applies QR and SVD factorizations to produce\n",
    "    trimmed versions of U and V.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    U : numpy.ndarray\n",
    "        The left singular vectors.\n",
    "    Sig : numpy.ndarray\n",
    "        The singular values.\n",
    "    V : numpy.ndarray\n",
    "        The right singular vectors.\n",
    "    mu_U : float\n",
    "        The threshold for the row norm of U.\n",
    "    mu_V : float\n",
    "        The threshold for the row norm of V.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    U_out : numpy.ndarray\n",
    "        The trimmed left singular vectors.\n",
    "    V_out : numpy.ndarray\n",
    "        The trimmed right singular vectors.\n",
    "    '''\n",
    "    m, r = U.shape\n",
    "    row_norm_square_U = np.sum(U**2, axis=1)\n",
    "    big_rows_U = row_norm_square_U > (mu_U * r / m)\n",
    "    U[big_rows_U, :] = (U[big_rows_U, :].T * ((mu_U * r / m) / np.sqrt(row_norm_square_U[big_rows_U]))).T\n",
    "\n",
    "    n, r = V.shape\n",
    "    row_norm_square_V = np.sum(V**2, axis=1)\n",
    "    big_rows_V = row_norm_square_V > (mu_V * r / n)\n",
    "    V[big_rows_V, :] = (V[big_rows_V, :].T * ((mu_V * r / n) / np.sqrt(row_norm_square_V[big_rows_V]))).T\n",
    "\n",
    "    Q1, R1 = qr(U, mode='economic')\n",
    "    Q2, R2 = qr(V, mode='economic')\n",
    "    U_temp, Sig_out, V_temp = svd(R1 @ Sig @ R2.T, full_matrices=False)\n",
    "    \n",
    "    U_out = Q1 @ U_temp\n",
    "    V_out = Q2 @ V_temp\n",
    "\n",
    "    return U_out, V_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AccAltProj(D, r, params):\n",
    "    '''\n",
    "    Performs accelerated alternating projection to compute a low-rank approximation\n",
    "    of the input matrix D, with the specified target rank r.\n",
    "    Parameters\n",
    "    ----------\n",
    "    D : numpy.ndarray\n",
    "        The input matrix, with shape (m, n).\n",
    "    r : int\n",
    "        The target rank of the low-rank approximation.\n",
    "    params : dict\n",
    "        A dictionary of algorithm parameters, including:\n",
    "        - niter : int, optional (default = 100)\n",
    "            The maximum number of iterations.\n",
    "        - eps : float, optional (default = 1e-5)\n",
    "            The convergence tolerance for the Frobenius norm of the residual.\n",
    "        - β : float, optional (default = 1/(2*np.cbrt(np.prod(D.shape)/4)))\n",
    "            The step size for updating the threshold ζ.\n",
    "        - β_init : float, optional (default = 4*β)\n",
    "            The initial value of the threshold scaling parameter.\n",
    "        - γ : float, optional (default = 0.7)\n",
    "            The decay rate for the additional threshold term.\n",
    "        - µ : list of floats, optional (default = [5])\n",
    "            The trimming thresholds for the left and right singular vectors,\n",
    "            if trimming is enabled.\n",
    "        - trimming : bool, optional (default = False)\n",
    "            Whether to perform trimming of the left and right singular vectors\n",
    "            after each iteration.\n",
    "    Returns\n",
    "    -------\n",
    "    L : numpy.ndarray\n",
    "        The low-rank approximation of the input matrix D, with shape (m, n).\n",
    "    S : numpy.ndarray\n",
    "        The sparse matrix representing the residuals of the approximation.\n",
    "    '''\n",
    "    niter = params.get('niter', 100)\n",
    "    eps = params.get('eps', 1e-5)\n",
    "    β = params.get('β', 1/(2*np.cbrt(np.prod(D.shape)/4)))\n",
    "    β_init = params.get('β_init', 4*β)\n",
    "    γ = params.get('γ', 0.7)\n",
    "    µ = params.get('µ', [5])\n",
    "    trimming = params.get('trimming', False)\n",
    "\n",
    "    ζ = β_init * svds(D, 1)[1][0]\n",
    "\n",
    "    S = hard_threshold(D, ζ)\n",
    "    U, Sigma, Vt = svds(D - S, r)\n",
    "    V = Vt.T\n",
    "    L = U @ np.diag(Sigma) @ Vt\n",
    "\n",
    "    ζ = β * Sigma[0]\n",
    "    S = hard_threshold(D - L, ζ)\n",
    "\n",
    "    out = np.empty(niter)\n",
    "    out[0] = norm(D - L - S,'fro')/norm(D,'fro')\n",
    "\n",
    "    for i in range(niter):\n",
    "        if trimming:\n",
    "            U, V = trim(U, np.diag(Sigma[:r]), V, µ[0], µ[-1])\n",
    "        \n",
    "        Z = D - S\n",
    "        Q1, R1 = qr((Z.T @ U - V @ (Z @ V).T @ U), mode='economic')\n",
    "        Q2, R2 = qr((Z @ V - U @ U.T @ Z @ V), mode='economic')\n",
    "\n",
    "        M = np.block([[U.T @ Z @ V, R1.T],\n",
    "                      [R2, np.zeros_like(R2)]])\n",
    "        \n",
    "        U_of_M, Sigma, V_of_M = svd(M, full_matrices=False)\n",
    "        \n",
    "        U = np.hstack([U, Q2]) @ U_of_M[:, :r]\n",
    "        V = np.hstack([V, Q1]) @ V_of_M[:, :r]\n",
    "        L = U @ np.diag(Sigma[:r]) @ V.T\n",
    "\n",
    "        ζ = β * (Sigma[r] + (γ**i) * Sigma[0])\n",
    "        S = hard_threshold(D - L, ζ)\n",
    "\n",
    "        out[i+1] = norm(D - L - S,'fro')/norm(D,'fro')\n",
    "\n",
    "        print(f'{i} {out[i+1]}')\n",
    "        \n",
    "        if out[i+1] < eps:\n",
    "            break\n",
    "              \n",
    "    return L, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(binary_mask, ground_truth):\n",
    "    assert binary_mask.shape == ground_truth.shape\n",
    "\n",
    "    binary_mask_flat = binary_mask.flatten()\n",
    "    ground_truth_flat = ground_truth.flatten()\n",
    "\n",
    "    ground_truth_flat[ground_truth_flat != 0] = 255\n",
    "\n",
    "    prec_pos = precision_score(ground_truth_flat, binary_mask_flat, pos_label=255,zero_division=0)\n",
    "    prec_neg = precision_score(ground_truth_flat, binary_mask_flat, pos_label=0,zero_division=0)\n",
    "    rec_pos = recall_score(ground_truth_flat, binary_mask_flat, pos_label=255,zero_division=0)\n",
    "    rec_neg = recall_score(ground_truth_flat, binary_mask_flat, pos_label=0,zero_division=0)\n",
    "\n",
    "    precision = (prec_pos + prec_neg) / 2\n",
    "    recall = (rec_pos + rec_neg) / 2\n",
    "\n",
    "    f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "    return {'precision': precision, 'recall': recall, 'f1_score': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(dataset, category, place, type):\n",
    "    path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,place,type)\n",
    "    image_paths = [os.path.join(path, img_name) for img_name in sorted(os.listdir(path)) if img_name != \".DS_Store\"]\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset, category, place, type):\n",
    "    image_paths = load_data_path(dataset, category, place, type)\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        im = cv2.imread(path)\n",
    "        gray_im  = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        gray_im = gray_im/255.0\n",
    "        images.append(gray_im)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling(image_paths,output_path,factor):\n",
    "    for i, path in enumerate(image_paths):\n",
    "       im = cv2.imread(path)\n",
    "       gray_im  = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "       downsampled_image = cv2.resize(gray_im, None, fx=factor, fy=factor, interpolation=cv2.INTER_AREA)\n",
    "       output_filepath = os.path.join(output_path,f\"{i+1:05}.png\")\n",
    "       cv2.imwrite(output_filepath, downsampled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_images(images):\n",
    "    stacked_images = np.stack(images, axis=-1)\n",
    "    n, m, k = stacked_images.shape\n",
    "    images_matrix = stacked_images.reshape(n*m, k)\n",
    "    return images_matrix, n, m, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(L, S, n, m, k, path):\n",
    "    L_frames = L.reshape((n*m, k))\n",
    "    S_frames = S.reshape((n*m, k))\n",
    "\n",
    "    if not os.path.exists(os.path.join(path,\"S\")):\n",
    "        os.makedirs(os.path.join(path,\"S\"))\n",
    "\n",
    "    if not os.path.exists(os.path.join(path,\"L\")):\n",
    "        os.makedirs(os.path.join(path,\"L\"))\n",
    "    \n",
    "    if not os.path.exists(os.path.join(path,\"BinaryMask\")):\n",
    "        os.makedirs(os.path.join(path,\"BinaryMask\"))\n",
    "\n",
    "    for i in range(k):\n",
    "        L_frame = L_frames[:, i].reshape(n, m)\n",
    "        S_frame = S_frames[:, i].reshape(n, m)\n",
    "\n",
    "        L_frame = (L_frame * 255).astype(np.uint8)\n",
    "        S_frame = (S_frame * 255).astype(np.uint8)\n",
    "\n",
    "        output_filepath = os.path.join(path,\"S\",f\"S{i+1:05}.png\")\n",
    "        cv2.imwrite(output_filepath, S_frame)\n",
    "\n",
    "        output_filepath = os.path.join(path,\"L\",f\"L{i+1:05}.png\")\n",
    "        cv2.imwrite(output_filepath, L_frame)\n",
    "\n",
    "        S_frame[S_frame>220] = 0\n",
    "        S_frame[S_frame>=50] = 255\n",
    "        S_frame[S_frame<50] = 0\n",
    "        \n",
    "        output_filepath = os.path.join(path,\"BinaryMask\",f\"BM{i+1:05}.png\")\n",
    "        cv2.imwrite(output_filepath, S_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_roi(path):\n",
    "    roi_path = os.path.join(path,\"temporalROI.txt\")\n",
    "    with open(roi_path, 'r') as f:\n",
    "        numbers = f.readline().strip().split(' ')\n",
    "        numbers = [int(num) for num in numbers]\n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(downsampled_groundtruths, binarymasks, roi):\n",
    "\n",
    "    sum_metrics = {\n",
    "    'precision': 0,\n",
    "    'recall': 0,\n",
    "    'f1_score': 0,\n",
    "    }\n",
    "\n",
    "    if roi == None:\n",
    "        roi = [1, len(downsampled_groundtruths)+1]\n",
    "\n",
    "    for i in range(roi[0]-1, roi[1]-1):\n",
    "        ground_truth = cv2.imread(downsampled_groundtruths[i])\n",
    "        ground_truth = cv2.cvtColor(ground_truth, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        binary_mask = cv2.imread(binarymasks[i])\n",
    "        binary_mask = cv2.cvtColor(binary_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        metrics = compute_metrics(binary_mask, ground_truth)\n",
    "        \n",
    "        for key in sum_metrics:\n",
    "            sum_metrics[key] += metrics[key]\n",
    "\n",
    "    average_metrics = {key: value / (roi[1]-roi[0]) for key, value in sum_metrics.items()}\n",
    "\n",
    "    return average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video(frames,path,frame_size):\n",
    "    codec = cv2.VideoWriter_fourcc(*'MJPG') \n",
    "    fps = 30\n",
    "    video_writer = cv2.VideoWriter(path, codec, fps, frame_size, isColor=False)\n",
    "    for frame in frames:\n",
    "        video_writer.write((frame * 255).astype(np.uint8))\n",
    "    video_writer.release()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"BMC\"\n",
    "category = \"synth2\"\n",
    "video_name = \"522\"\n",
    "place = '522'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"BMC\"\n",
    "category = \"real\"\n",
    "video_name = \"Video_001\"\n",
    "place = 'Video_001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_file, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the video file.\")\n",
    "        return\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        output_path = os.path.join(output_dir, f\"{i+1:05}.png\")\n",
    "        cv2.imwrite(output_path, frame)\n",
    "        i += 1\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "video_file = os.path.join(os.getcwd(),\"Dataset\",dataset,category,video_name+\".mp4\")\n",
    "output_path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,place,\"input\")\n",
    "\n",
    "video_to_frames(video_file, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = os.path.join(os.getcwd(),\"Dataset\",dataset,category,video_name+\"_gt.mp4\")\n",
    "output_path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,video_name,\"groundtruth\")\n",
    "\n",
    "video_to_frames(video_file, output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDnet2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"CDnet2012\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"baseline\"\n",
    "place = \"PETS2006\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"dynamicBackground\"\n",
    "place = \"boats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"intermittentObjectMotion\"\n",
    "place = \"sofa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"shadow\"\n",
    "place = \"copyMachine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"thermal\"\n",
    "place = \"corridor\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 0.5\n",
    "\n",
    "output_path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,place,\"downsampled_input\")\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "input_paths = load_data_path(dataset,category,place,\"input\")\n",
    "downsampling(input_paths,output_path,factor)\n",
    "\n",
    "output_path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,place,\"downsampled_groundtruth\")\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "ground_truth_paths = load_data_path(dataset,category,place,\"groundtruth\")\n",
    "downsampling(ground_truth_paths,output_path,factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_images = load_data(dataset,category,place,\"downsampled_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_matrix, n, m, k = stack_images(downsampled_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 1\n",
    "µ = [1,100]\n",
    "result = \"result1_100_1-0.3\"\n",
    "params = {\n",
    "    'β_init': r*np.sqrt(µ[0]*µ[1])/(1*np.sqrt(n*m*k)),\n",
    "    'β': r*np.sqrt(µ[0]*µ[1])/(4*np.sqrt(n*m*k)),\n",
    "    'µ': µ,\n",
    "    'trimming': True,\n",
    "    'eps': 1e-4,\n",
    "    'γ': 0.3,\n",
    "    'niter': 3000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, S = AccAltProj(frame_matrix, r, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,place,result)\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "save_output(L, S, n, m, k, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,place)\n",
    "if dataset == \"BMC\":\n",
    "    roi = None\n",
    "else:\n",
    "    roi = load_roi(path)\n",
    "downsampled_groundtruths = load_data_path(dataset,category,place,\"downsampled_groundtruth\")\n",
    "binarymasks = load_data_path(dataset,category,place,result+\"/BinaryMask\")\n",
    "average_metrics = evaluate(downsampled_groundtruths, binarymasks, roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,place,result,\"Background.avi\")\n",
    "L_frames = load_data(dataset,category,place,result+\"/L\")\n",
    "save_video(L_frames,output_path,(m,n))\n",
    "\n",
    "output_path = os.path.join(os.getcwd(),\"Dataset\",dataset,category,place,result,\"Foreground.avi\")\n",
    "Mask_frames = load_data(dataset,category,place,result+\"/BinaryMask\")\n",
    "save_video(Mask_frames,output_path,(m,n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_frames = load_data(dataset,category,place,result+\"/L\")\n",
    "downsampled_images = load_data(dataset,category,place,\"downsampled_input\")[0]\n",
    "downsampled_images = (downsampled_images * 255.0)\n",
    "sim = 0\n",
    "psnr_score = 0\n",
    "for i in range(len(L_frames)):\n",
    "    background = (L_frames[i] * 255.0)\n",
    "    sim += ssim(downsampled_images, background, data_range=background.max() - background.min())\n",
    "    psnr_score += psnr(downsampled_images, background, data_range=background.max() - background.min())\n",
    "sim = sim/len(L_frames)\n",
    "psnr_score = psnr_score/len(L_frames)\n",
    "print(f\"ssim: {sim}\\npsnr: {psnr_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
